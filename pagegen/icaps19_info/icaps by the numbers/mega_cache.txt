paper title abstract algorithm selection in optimization and  application to angry birds consider the maxscore algorithm selection problem: given some optimization problem instances, a set of algorithms that solve them, and a time limit, what is the optimal policy for selecting (algorithm, instance) runs so as to maximize the sum of solution qualities for all problem instances? we analyze the computational complexity of restrictions of maxscore (np-hard), and provide a dynamic programming approximation algorithm. this algorithm, as well as new greedy algorithms, are evaluated empirically on data from agent runs on angry birds problem instances. results show a significant improvement over a hyper-agent greedy scheme from related work. efﬁcient heuristic search for optimal environment redesign given an environment, the utility measure of the agents acting within it, a set of possible environment modifications, and a description of design constraints, the objective of equi-reward utility maximizing design (er-umd) is to find a valid sequence of modifications to apply to the environment in order to maximize agent utility. to efficiently traverse the typically large space of possible design options, we use heuristic search and propose new heuristics, which relax the design process; instead of computing the value achieved by a single modification, we use a dominating modification guaranteed to be at least as beneficial. the proposed technique enables heuristic caching for similar nodes thereby saving computational overhead. we specify sufficient conditions under which our approach is guaranteed to produce admissible estimates, and describe a range of models that comply with these requirements. also, for models with lifted representations of environment modifications, we provide simple methods to automatically generate dominating modifications. we evaluate our approach on a range of stochastic settings for which our heuristic is admissible. we demonstrate its efficiency by comparing it to a previously suggested heuristic, that employs a relaxation of the environment, and to a compilation from er-umd to planning. robust operations management on mars we compare both deterministic and robust stochastic approaches to the problem of scheduling a set of scientific tasks under processing time uncertainty. while dealing with strict time windows and minimum transition time constraints, we provide closed-form expressions to compute the exact probability that a solution has to remain feasible. experiments, taking uncertainty on the stochastic knowledge itself into account, are conducted on real instances involving the constraints faced and objectives pursued during a recent two-week mars analog mission in the desert of utah, usa. the results reveal that, even when using very bad approximations of probability distributions, solutions computed from the stochastic models we introduce, significantly outperform the ones obtained from a classical deterministic formulation, while preserving most of the solution’s quality. quantifying degrees of controllability in temporal networks with uncertainty controllability for simple temporal networks with uncertainty (stnus) has thus far been limited to three levels: strong, dynamic, and weak. because of this, there is currently no systematic way for an agent to assess just how far from being controllable an uncontrollable stnu is. we use a new geometric interpretation of stnus to introduce the degrees of strong and dynamic controllability – continuous metrics that measure how far a network is from being controllable. we utilize these metrics to approximate the probabilities that an stnu can be dispatched successfully offline and online respectively. we introduce new methods for predicting the degrees of strong and dynamic controllability for uncontrollable networks. in addition, we show empirically that both metrics are good predictors of the actual dispatch success rate. replanning for situated robots planning enables intelligent agents, such as robots, to act so as to achieve their long term goals. to make the planning process tractable, a relatively low fidelity model of the world is often used, which sometimes leads to the need to replan. the typical view of replanning is that the robot is given the current state, the goal, and possibly some data from the previous planning process. however, for robots (or teams of robots) that exist in continuous physical space, act concurrently, have deadlines, or must otherwise consider durative actions, things are not so simple. in this paper, we address the problem of replanning for situated robots. relying on previous work on situated temporal planning, we frame the replanning problem as a situated temporal planning problem, where currently executing actions are handled via timed initial literals (tils), under the assumptions that actions cannot be interrupted. we then relax this assumption, and address situated replanning with interruptible actions. we bridge the gap between the low-level model of the robot and the high-level model used for planning by the novel notion of a bail out action generator, which relies on the low-level model to generate high-level actions that describe possible ways to interrupt currently executing actions. because actions can be interrupted at different times during their execution, we also propose a novel algorithm to handle temporal planning with time-dependent durations. backward sequence analysis for single-armed cluster tools this paper analyzes a backward sequence for single-armed cluster tools with processing time variations. we first define a fundamental cycle with the backward sequence and derive a formula for the cycle time by considering processing time variations. we then develop conditions for which the backward sequence is optimal. the upper bound on the average cycle time from the backward sequence is also analyzed. we then show experimentally that the sequence performs well even with processing time variations. on the pathological search behavior of distributed greedy best first search although a* search can be efficiently parallelized using methods such as hash-distributed a* (hda*), distributed parallelization of greedy best first search (gbfs), a sub-optimal search which often finds solutions much faster than a*, has received little attention. we show that surprisingly, hdgbfs, an adaptation of hda* to gbfs, often performs significantly worse than sequential gbfs. we analyze and explain this performance degradation, and propose a novel method for distributed parallelization of gbfs, which significantly outperforms hdgbfs. a hierarchical approach to active semantic mapping using probabilistic logic and information reward pomdps maintaining a semantic map of a complex and dynamic environment, where the uncertainty originates in both noisy perception and unexpected changes, is a challenging problem. in particular, we focus on the problem of maintaining a semantic map of an environment by a mobile agent. in this paper we address this problem in a hierarchical fashion. firstly, we employ a probabilistic logic model representing the semantic map, as well as the associated uncertainty. secondly, we model the interaction of the robot with the environment with a set of information-reward pomdp models, one for each partition of the environment (e.g., a room). the partition is performed in order to address the scalability limitations of pomdp models over very large state spaces. we then use probabilistic inference to determine which pomdp and policy to execute next. experimental results show the efficiency of this architecture in real domestic service robotic scenarios. an empirical study of perfect potential heuristics potential heuristics are weighted functions over state features of a planning task. a recent study defines the complexity of a task as the minimum required feature complexity for a potential heuristic that makes a search backtrack-free. this gives an indication of how complex potential heuristics need to be to achieve good results in satisficing planning. however, these results do not directly transfer to optimal planning. in this paper, we empirically study how complex potential heuristics must be to represent the perfect heuristic and how close to perfect heuristcs can get with a limited number of features. we aim to identify the practical trade-offs between size, complexity and time for the quality of potential heuristics. our results show that, even for simple planning tasks, finding perfect potential heuristics might be harder than expected. mars on-site shared analytics, information, and computing we study the use of distributed computation in a representative multi-robot planetary exploration mission. we model a network of small rovers with access to computing resources from a static base station based on current design efforts and extrapolation from the mars 2020 rover autonomy. the key algorithmic problem is simultaneous scheduling of computation, communication, and caching of data, as informed by an autonomous mission planner. we consider minimum makespan scheduling and present a consensus-backed scheduler for shared-world, distributed scheduling based on an integer linear program. we validate the pipeline with simulation and field results. our results are intended to provide a baseline comparison and motivating application domain for future research into network-aware decentralized scheduling and resource allocation. error-tolerant anytime approach for plan recognition using a particle filter classical plan recognition approaches require restrictive assumptions and are generally off-line. however, many real-world applications of plan recognition need to deal with real-time constraints, noisy information, temporal relations in actions, agent preferences, and so on. many existing approaches tried to relax assumptions, but none can deal with all previously cited needs. this paper proposes an extension of previous works on plan recognition based on plan tree grammar. our anytime top-down approach uses a particle filter. this approach manages to give a quick reliable solution to the plan recognition problem while dealing with noisy observations and without reducing the expressiveness of plan libraries. we show empirical evidence of efficiency by using this approach on simulated problems. planning with global state constraints and state-dependent action costs planning with global state constraints refers to an extension of classical planning in which some properties of each state are derived via a set of equations, rules or constraints. this extension enables more elegant modeling of networked physical systems such as power grids. so far, planning research in this setting focused on domains where action costs are constant, rather than a function of a state in which the action is applied. this restriction prevents us from accurately specifying the objective in some real-world domains, leading to generation of sub-optimal plans. for example, when reconfiguring a power network, we often need to temporarily leave some users without electricity for a certain amount of time, and in such circumstances it is desirable to reduce the unsupplied load over the total time span. this preference can be expressed using state-dependent action costs. we extend planning with global state constraints to include state-dependent action costs, adapt abstraction heuristics to this setting, and show improved performance on a set of problems. towards stable symbol grounding with zero-suppressed state autoencoder while classical planning has been an active branch of ai, its applicability is limited to the tasks precisely modeled by humans. fully automated high-level agents should be instead able to find a symbolic representation of an unknown environment without supervision, otherwise it exhibits the knowledge acquisition bottleneck. meanwhile, latplan (asai and fukunaga 2018) partially resolves the bottleneck with a neural network called state autoencoder (sae). sae obtains the propositional representation of the image-based puzzle domains with unsupervised learning, generates a state space and performs classical planning. in this paper, we identify the problematic, stochastic behavior of the sae-produced propositions as a new sub-problem of symbol grounding problem, the symbol stability problem. informally, symbols are stable when their referents (e.g. propositional values) do not change against small perturbation of the observation, and unstable symbols are harmful for symbolic reasoning. we analyze the problem in latplan both formally and empirically, and propose “zero-suppressed sae”, an enhancement that stabilizes the propositions. we show that it finds the more stable propositions and the more compact representations, resulting in an improved success rate of latplan. it is robust against various hyperparameters and eases the tuning effort, and also provides a weight pruning capability as a side effect. tree-rex: sat-based tree exploration for efficient and high-quality htn planning in this paper, we propose a novel sat-based planning approach to solve totally ordered hierarchical planning problems. our approach called "tree-like reduction exploration" (tree-rex) makes two contributions: (1) it allows us to rapidly solve hierarchical planning problems by making effective use of incremental sat solving, and (2) it implements an anytime approach that gradually improves plan quality (makespan) as time resources are allotted. incremental sat solving is important as it reduces the encoding volume of planning problems, it builds on information obtained from previous search iterations and speeds up the search for plans. we show that tree-rex outperforms state-of-the-art sat-based htn planning with respect to run times and plan quality on most of the considered ipc domains. explicability? legibility? predictability? transparency? privacy? security? the emerging landscape of interpretable robot behavior there has been significant interest of late in generating behavior of agents that is interpretable to the human (observer) in the loop. however, the work in this area has typically lacked coherence on the topic, with proposed solutions for “explicable”, “legible”, “predictable” and “transparent” planning with overlapping, and sometimes conflicting, semantics all aimed at some notion of understanding what intentions the observer will ascribe to an agent by observing its behavior. this is also true for the recent works on “security” and “privacy” of plans which are also trying to answer the same question, but from the opposite point of view – i.e. when the agent is trying to hide instead of reveal its intentions. this paper attempts to provide a workable taxonomy of relevant concepts in this exciting and emerging field of inquiry. improving the combination of jps and geometric containers the jps family of grid-based pathfinding algorithms can be improved with preprocessing methods such as geometric containers. however, such enhancements require a dijkstra search for every node in the grid and the space and time costs of all this additional computation can be prohibitive. in this work we consider an alternative approach where we run dijkstra only from every node where a jump point is located. we also compute and store geometric containers only for those outgoing edges which are consistent with the diagonal-first ordering in jps. since the number of jump points on a grid is usually much smaller than the total number of grid cells, we can save up to orders of magnitude of time and space. in addition to improving preprocessing overheads, we also present a partial expansion strategy which can improve the performance of online search by reducing the total number of operations on the open list. mixed discrete continuous non-linear planning through piecewise linear approximation reasoning with numeric quantities that change continuously is vital to the application of planners in many real-world scenarios. therefore, over recent years there has been a significant push, resulting in the development of several planners capable of handling this. scalability remains a challenge for such planners, especially those capable of reasoning with non-linear numeric change. in this paper, we present a novel approach to reasoning with non-linear domains. using linear over and under-estimators to bound the problem, allowing us to use scalable planners that handle linear change to find plans for non-linear domains. we compare the performance of our approach to existing planners capable of reasoning with non-linear change on several domains and demonstrate that our planner can achieve state-ofthe-art performance in non-linear planning. personalized medication and activity planning in pddl+ the emergence of planners capable of reasoning with continuous dynamics, as expressed in pddl+, has increased the range of problems that fall within the capabilities of pddl planners. one such problem is planning patients’ activities and medication regimes, considering non-linear medication pharmacokinetics. in this paper we explore the application of contemporary pddl+ planners to this problem. to address their performance limitations, we present a linearize–validate cycle; tasks are solved by iterative refinement of a linear approximation of the domain, solved by a linear planner, then validated at each stage against the full non-linear semantics. in doing this we allow this domain to fall within the capabilities of current planners; and in our evaluation we use optic to demonstrate this. subset-saturated cost partitioning for optimal classical planning cost partitioning is a method for admissibly adding multiple heuristics for state-space search. saturated cost partitioning considers the given heuristics in sequence, assigning to each heuristic the minimum fraction of remaining costs that it needs to preserve its estimates for all states. we generalize saturated cost partitioning by allowing to preserve the heuristic values of only a subset of states and show that this often leads to stronger heuristics. temporal brittleness analysis of task networks for planetary rovers we propose a new method to analyze the temporal brittleness of task networks, which allows the detection and enumeration of activities that, with modest task execution duration variation make the execution of the task network dynamically uncontrollable. in this method, we introduce a metric for measuring an activity brittleness – defined as the degree of acceptable deviation of its nominal duration – and describe how that measurement is mapped to task network structure. complementary to existing work on plan robustness analysis which informs how likely a task network is to succeed or not, the proposed analysis and metric go deeper to pinpoint the sources of potential brittleness due to temporal constraints and to focus either human designers and/or automated task network generators (e.g. scheduler/planners) to address sources of undesirable brittleness. we apply the approach to a set of task networks (called sol types) in development for nasa’s next planetary rover and present common patterns that are sources of brittleness. these techniques are currently under evaluation for potential use supporting operations of the mars 2020 rover. efficiently exploring ordering problems through conflict-directed search in planning and scheduling, solving problems with both state and temporal constraints is hard, since they may be highly coupled. judicious orderings of events enable solvers to efficiently make decisions over sequences of actions to satisfy complex hybrid specifications. the ordering problem is thus fundamental to planning. promising recent works have explored the ordering problem as search, incorporating a special tree structure for efficiency. however, such approaches only reason over partial order specifications. having observed that an ordering is inconsistent with respect to underlying constraints, prior works do not exploit the tree structure to efficiently generate orderings which resolve the inconsistencies. in this paper, we present conflict-directed incremental total ordering (cdito), a conflict-directed search method to incrementally and systematically generate event total orders given ordering constraints and conflicts returned by sub-solvers. due to its ability to reason over these conflicts, cdito is much more efficient than incremental total ordering. we demonstrate this by benchmarking on temporal network configuration problems that involve routing network flows and managing bandwidth resources over time. optimizing parameters for uncertain execution and rescheduling robustness we describe the application of using monte carlo simulation to optimize a schedule for both execution and rescheduling robustness and activity score in the face of execution uncertainties. we apply these techniques to the problem of optimizing a schedule for a planetary rover with very limited onboard computation. we search in the activity input parameter space where a) the onboard scheduler is a one shot non-backtracking scheduler in which once an activity is placed it is never moved or deleted and b) the activity priority determines the order in which activities are considered for placement in the schedule. we show that simulation driven search for activity parameters outperforms alternative schemes that use static priority assignment. our approach can be viewed as using simulation feedback to determine problem specific heuristics much like squeaky wheel optimization. these techniques are currently baselined for use in the ground operations of nasa's next planetary rover, the mars 2020 rover. lazy cbs: implict conflict-based search using lazy clause generation conflict-based search (cbs) is a effective approach to optimal multi-agent path finding. however, performance of cbs approaches degrade rapidly in highly-contended graphs with many agents. one of the reasons this occurs is that cbs does not detect independent subproblems; i.e. it can re-solve the same conflicts between the same pairs of agents up to exponentially many times, each time along a different branch. constraint programming approaches with nogood learning avoid this kind of duplication of effort by storing nogoods that record the reasons for conflicts. this can exponentially reduce search in constraint programming. in this work, we present lazy cbs, a new approach to multi-agent pathfinding which replaces the high-level solver of cbs with a lazily constructed constraint programming model with nogoods. we use core-guided depth-first search to explore the space of conflicts and we detect along each branch reusable nogoods which help to quickly identify feasible solutions. our experiments show that lazy cbs can significantly improve on the state-of-the-art for optimal mapf problems under the sumof-costs metric, especially in cases where there exists significant contention. tabu-based large neighbourhood search for time/sequence-dependent scheduling problems with time windows an important class of scheduling problems is characterised by time-dependency and/or sequence-dependency with time windows. we introduce and analyze four algorithmic ideas for this class: a novel hybridization of adaptive large neighbourhood search (alns) and tabu search (ts), randomized generic neighbourhood operators, a partial sequence dominance heuristic, and a fast insertion strategy. an evaluation of the resulting hybrid algorithm on two domains, a realworld multi-orbit agile earth observation satellite scheduling problem, and an order acceptance and scheduling problem, shows that it robustly outperforms a mixed integer programming method, a two-stage hybridization of alns and ts, and recent state-of-the-art metaheuristic methods. the clustered dial-a-ride problem we study a generalization of the classical dial-a-ride problem, with an application to public transport planning in rural areas. in the classical dial-a-ride problem, n users each specify a pick-up and a delivery location, and the aim is to plan the least cost route to cater all requests. this can be modeled as a traveling salesmen problem in a complete graph with precedence constraints (pick-ups need to happen before deliveries). in this paper, we consider the clustered dial-a-ride problem, where we do not operate on a complete graph but on a graph composed of serially numbered cliques where each clique is connected to the next one via a single edge. this setting is inspired by door-to-door transportation for people from remote villages who want to get to another village or the next city by a bus which operates on demand. we argue that in case the optimal route exhibits certain structural properties, it can be computed significantly faster. to make use of this observation, we devise a classification algorithm which can decide whether the optimal route exhibits these structural properties before computing it. extensive experiments on artificial and real-world instances reveal that the majority of optimal routes indeed have the desired properties and that our classifier is an efficient tool to recognize the respective instances. propagating piecewise-linear weights in temporal networks this paper presents a novel technique using piecewise-linear functions (plfs) as weights on edges in the graphs of two kinds of temporal networks to solve several previously open problems. generalizing constraint-propagation rules to accommodate plf weights requires implementing a small handful of functions. most problems are solved by inserting one or more edges with an initial unknown weight (represented as a variable), and then using the modified rules to propagate the plf weights. for one kind of network, a new set of propagation rules is introduced to avoid a non-termination issue that arises when propagating plf weights. the paper also presents two new results for determining the tightest horizon that can be imposed while preserving a network's dynamic consistency/controllability. exact methods for extended rotating workforce scheduling problems in many professions daily demand for different shifts varies during the week. the rotating workforce scheduling problem deals with the creation of repeating schedules for such demand and is therefore of high practical relevance. this paper investigates solving this real-life problem with several new practically relevant features. this includes early recognition of certain infeasibility criteria, complex rest time constraints regarding weekly rest time, and optimization goals to deal with optimal assignments of free weekends. we introduce a state-of-the-art constraint model and evaluate it with different extensions. the evaluation shows that many real-life instances can be solved to optimality using a constraint solver. our approach is under deployment in a state-of-the-art commercial solver for rotating workforce scheduling. relaxed bdds: an admissible heuristic for delete-free planning based on a discrete relaxation we investigate the use of relaxed binary decision diagrams (bdds) as an alternative to linear programming (lp) for computing an admissible heuristic for the cost-optimal delete-free planning (dfp) problem. our main contributions are the introduction of a novel bdd encoding, a construction algorithm for the sequential relaxation of a dfp task and a study of the effectiveness of relaxed bdd heuristics, both from a theoretical and practical perspective. we further show that relaxed bdds can be used beyond heuristic computation to extract delete-free plans, find action landmarks, and identify redundant actions. our empirical analysis shows that while bdd-based heuristics trail the state of the art, even small relaxed bdds are competitive with the lp heuristic for the dfp task. deep policies for width-based planning in pixel domains width-based planning has demonstrated great success in recent years due to its ability to scale independently of the size of the state space. for example, bandres et al. (2018) introduced a rollout version of the iterated width algorithm whose performance compares well with humans and learning methods in the pixel setting of the atari games suite. in this setting, planning is done on-line using the “screen” states and selecting actions by looking ahead into the future. however, this algorithm is purely exploratory and does not leverage past reward information. furthermore, it requires the state to be factored into features that need to be pre-defined for the particular task, e.g., the b-prost pixel features. in this work, we extend width-based planning by incorporating an explicit policy in the action selection mechanism. our method, called π-iw, interleaves width-based planning and policy learning using the state-actions visited by the planner. the policy estimate takes the form of a neural network and is in turn used to guide the planning step, thus reinforcing promising paths. surprisingly, we observe that the representation learned by the neural network can be used as a feature space for the width-based planner without degrading its performance, thus removing the requirement of pre-defined features for the planner. we compare π-iw with previous width-based methods and with alphazero in simple environments and show that π-iw has superior performance. we also show that our proposed algorithm outperforms previous width-based methods in the pixel setting of atari games suite. model recognition as planning given a partially observed plan execution, and a set of possible planning models (models that share the same state variables but different action schemata), model recognition is the task of identifying the model that explains the observation. the paper formalizes this task and introduces a novel method that estimates the probability of a strips model to produce an observation of a plan execution. this method builds on top of off-the-shelf classical planning algorithms and it is robust to missing actions and intermediate states in the observation. the effectiveness of the method is tested in three experiments, each encoding a set of different strips models and all using empty-action observations: (1) a classical string classification task; (2) identification of the model that encodes a failure present in an observation; and (3) recognition of a robot navigation policy. towards automating crime prevention through environmental design (cpted) analysis to predict burglary the design of the built environment (such as housing developments, street networks) can increase the opportunity for crime and disorder to occur. for example, a housing development with poor surveillance can provide an opportunity for offenders to commit residential burglary and avoid detection. crime prevention through environmental design (cpted) aims to reduce crime and disorder through the design and manipulation of the built environment. the police typically play an important role in the delivery and application of cpted by assessing planning applications, identifying design features that may provide an opportunity for crime and offering remedial advice. in england and wales, it is common practice for police specialists – designing out crime officers (docos) – to review architectural site plans during the planning process. however, owing to significant cuts to policing budgets, the number of docos in post is reducing whilst the demand for new housing is on the increase. in this novel work, it is demonstrated that key knowledge about the opportunities for crime and disorder within the built environment can be elicited from a purposive sample of 28 experienced docos, encoded in a domain model and utilised by automated planning techniques to automatically assess architectural site plans for future crime risk. a theoretical and algorithmic analysis of configurable mdps this paper analyzes, from theoretical and algorithmic perspectives, a class of problems recently introduced in the literature of markov decision processes—configurable markov decision processes. in this new class of problems we jointly optimize the probability transition function and associated optimal policy, in order to improve the performance of a decision-making agent. we contribute a complexity analysis on the problem from a computational perspective, where we show that, in general, solving a configurable mdp is np-hard. we also discuss practical challenges often faced in solving this class of problems. additionally, we formally derive a gradient-based approach that sheds some light on the correctness and limitations of existing methods. we conclude by demonstrating the application of different parameterizations of configurable mdps in two scenarios, offering a discussion on advantages and drawbacks from modeling and algorithmic perspectives. our contributions set the foundation for a better understanding of this recent problem, and the wider applicability of the underlying ideas to different planning problems. provable infinite-horizon real-time planning for repetitive tasks in manufacturing and automation settings, robots often have to perform highly-repetitive manipulation tasks in structured environments. in this work we are interested in settings where tasks are similar, yet not identical (e.g., due to uncertain orientation of objects) and motion planning needs to be extremely fast. preprocessing-based approaches prove to be very beneficial in these settings—they analyze the configuration-space offline to generate some auxiliary information which can then be used in the query phase to speedup planning times. typically, the tighter the requirement is on query times the larger the memory footprint will be. in particular, for high-dimensional spaces, providing real-time planning capabilities is extremely challenging. while there are planners that guarantee real-time performance by limiting the planning horizon, we are not aware of general-purpose planners capable of doing it for infinite horizon (i.e., planning to the goal). to this end, we propose a preprocessingbased method that provides provable bounds on the query time while incurring only a small amount of memory overhead in the query phase. we evaluate our method on a 7-dof robot arm and show a speedup of over tenfold in query time when compared to the prm algorithm, while provably guaranteeing a maximum query time of less than 3 milliseconds. towards a unified view of ai planning and reactive synthesis ai automated planning and reactive synthesis are well established techniques for sequential decision making. in this paper we examine a collection of ai planning problems with temporally extended goals, specified in linear temporal logic (ltl). we characterize these so-called ltl planning problems as two-player games and thereby establish their correspondence to reactive synthesis problems. this unifying view furthers our understanding of the relationship between plan and program synthesis, establishing complexity results for ltl planning tasks. building on this correspondence, we identify restricted fragments of ltl for which plan synthesis can be realized more efficiently. online risk-bounded motion planning for autonomous vehicles in dynamic environments a crucial challenge to efficient and robust motion planning for autonomous vehicles is understanding the intentions of the surrounding agents. ignoring the intentions of the other agents in dynamic environments can lead to risky or overconservative plans. in this work, we model the motion planning problem as a partially observable markov decision process (pomdp) and propose an online system that combines an intent recognition algorithm and a pomdp solver to generate risk-bounded plans for the ego vehicle navigating with a number of dynamic agent vehicles. the intent recognition algorithm predicts the probabilistic hybrid motion states of each agent vehicle over a finite horizon using bayesian filtering and a library of pre-learned motion models. we update the pomdp model with the intent recognition results in real time and solve it using a heuristic search algorithm which produces policies with upper-bound guarantees on the probability of colliding with other dynamic agents. we demonstrate that our system is able to generate better motion plans in terms of efficiency and safety in a number of challenging environments including unprotected intersection left turns and lane changes as compared to the baseline methods. stochastic planning with lifted symbolic trajectory optimization this paper investigates online stochastic planning for problems with large factored state and action spaces. one promising approach in recent work estimates the quality of applicable actions in the current state through aggregate simulation from the states they reach. this leads to significant speedup, compared to search over concrete states and actions, and suffices to guide decision making in cases where the performance of a random policy is informative of the quality of a state. the paper makes two significant improvements to this approach. the first, taking inspiration from lifted belief propagation, exploits the structure of the problem to derive a more compact computation graph for aggregate simulation. the second improvement replaces the random policy embedded in the computation graph with symbolic variables that are optimized simultaneously with the search for high quality actions. this expands the scope of the approach to problems that require deep search and where information is lost quickly with random steps. an empirical evaluation shows that these ideas significantly improve performance, leading to state of the art performance on hard planning problems. landmark-enhanced heuristics for goal recognition in incomplete domain models recent approaches to goal recognition have progressively relaxed the assumptions about the amount and correctness of domain knowledge and available observations, yielding accurate and efficient algorithms. these approaches, however, assume completeness and correctness of the domain theory against which their algorithms match observations: this is too strong for most real-world domains. in this paper, we develop goal recognition techniques that are capable of recognizing goals using incomplete domain theories by considering different notions of planning landmarks in such domains. we evaluate the resulting techniques empirically in a large dataset of incomplete domains, and perform an ablation study to understand their effect on recognition performance. using fastmap to solve graph problems in a euclidean space it is well known that many graph problems, like the traveling salesman problem, are easier to solve in a euclidean space. this motivates the idea of quickly preprocessing a given graph by embedding it in a euclidean space to solve graph problems efficiently. in this paper, we study a near-linear time algorithm, called fastmap, that embeds a given non-negative edge-weighted undirected graph in a euclidean space and approximately preserves the pairwise shortest path distances between vertices. the euclidean space can then be used either for heuristic guidance of a* (as suggested previously) or for geometric interpretations that facilitate the application of techniques from analytical geometry. we present a new variant of fastmap and compare it with the original variant theoretically and empirically. we demonstrate its usefulness for solving a path-finding and a multi-agent meeting problem. disjoint splitting for multi-agent path finding with conflict-based search multi-agent path finding (mapf) is the planning problem of finding collision-free paths for a team of agents. we focus on conflict-based search (cbs), a two-level tree-search state-of-the-art mapf algorithm. the standard splitting strategy used by cbs is not disjoint, that is, when it splits a problem into two subproblems, some solutions are shared by both subproblems, which can create duplication of search effort. in this paper, we demonstrate how to improve cbs with disjoint splitting and how to modify the low-level search of cbs to take maximal advantage of it. experiments show that disjoint splitting increases the success rates and speeds of cbs and its variants by up to 3 orders of magnitude. learning scheduling models from event data a significant challenge in declarative approaches to scheduling is the creation of a parameterized model: the set of resources and their capacities and the types of activities and their temporal and resource requirements. in practice, such models are developed manually by skilled consultants and used repeatedly to solve different problem instances. for example, in a factory, the model may be used each day to schedule the current customer orders. in this work, we aim to automate the creation of such models by learning them from event data. we introduce a novel methodology that combines process mining, timed petri nets (tpns), and constraint programming (cp). the approach learns a sub-class of tpn from event logs of executions of past schedules and maps the tpn to a broad class of scheduling problems. we show how any problem of the scheduling class can be converted to a cp model. with new instance data (e.g., the day’s orders), the cp model can then be solved by an off-the-shelf solver. our approach provides an end-to-end solution, going from event logs to model-based optimal schedules. to demonstrate the value of the methodology we conduct experiments in which we learn and solve scheduling models from two types of data: event logs generated from job-shop scheduling benchmarks and real-world event logs from an outpatient hospital. unsupervised grounding of plannable first-order logic representation from images recently, there is an increasing interest in obtaining the relational structures of the environment in the reinforcement learning community. however, the resulting “relations” are not the discrete, logical predicates compatible to the symbolic reasoning such as classical planning or goal recognition. meanwhile, latplan (asai and fukunaga 2018) bridged the gap between deep-learning perceptual systems and symbolic classical planners. one key component of the system is a neural network called state autoencoder (sae), which encodes an image-based input into a propositional representation compatible to classical planning. to get the best of both worlds, we propose first-order state autoencoder, an unsupervised architecture for grounding the first-order logic predicates. each predicate models a relationship between objects by taking the interpretable arguments and returning a propositional value. in the experiment using 8-puzzle and a photorealistic blocksworld environment, we show that (1) the resulting predicates capture the interpretable relations (e.g. spatial), (2) they help obtaining the compact, abstract model of the environment, and finally, (3) the resulting model is compatible to symbolic classical planning. theoretical foundations for structural symmetries of lifted pddl tasks we transfer the notion of structural symmetries to lifted planning task representations, based on abstract structures which we define to model planning tasks. we show that symmetries are preserved by common grounding methods and we shed some light on the relation to previous symmetry concepts used in planning. using a suitable graph representation of lifted tasks, our experimental analysis of common planning benchmarks reveals that symmetries occur in the lifted representation of many domains. our work establishes the theoretical ground for exploiting symmetries beyond their previous scope, such as for faster grounding and mutex generation, as well as for state space transformations and reductions. a factored approach to contingent multi-agent planning collaborative multi-agent planning (map) under uncertainty with partial observability is a notoriously difficult problem. such map problems are often modeled as decpomdps, or its qualitative variant, qdec-pomdp, which is essentially a map version of contingent planning. the qdecpomdp model was introduced with the hope that its simpler, non-probabilistic structure will allow for better scalability. indeed, the recent imap algorithm scales much better than comparable dec-pomdp algorithms (bazinin and shani 2018). in this work we suggest a new approach to solving qdec-pomdps based on problem factoring. first, we find a solution to a map problem where the results of all observations are known to all agents. this is essentially a single-agent planning problem for the entire team. then, we project the solution tree into sub-trees, one per agent, and let each agent transform its projected tree into a legal local tree. if all agents succeed, we combine the trees into a valid joint-plan. otherwise, we continue to explore the space of team solutions. this approach is sound, complete, and as our empirical evaluation demonstrates, scales better than the imap algorithm. on the relation between star-topology decoupling and petri net unfolding petri net unfolding expands concurrent sub-threads of a transition system separately. in ai planning, star-topology decoupling (std) finds a partitioning of state variables into components whose dependencies take a star shape, and expands leafcomponent state spaces separately. thus both techniques rely on the separate expansion of state-space composites. how do they relate? we show that, provided compatible search orderings, std state space size dominates that of unfolding if every component contains a single state variable, and unfolding dominates std in the absence of prevail conditions (nondeleted action preconditions). in all other cases, exponential state space size advantages are possible on either side. thus the sources of exponential advantages of std are exactly a) state space size in the presence of prevail conditions (our results), and b) decidability of reachability in time linear in state space size vs. np-hard for unfolding (known results). temporal planning as refinement-based model checking planning as model checking based on source-to-source compilations has found increasing attention. previously proposed approaches for temporal and hybrid planning are based on static translations, in the sense that the resulting model checking problems are uniquely defined by the given input planning problems. as a drawback, the translations can become too large to be efficiently solvable. in this paper, we address propositional temporal planning, lifting static translations to a more flexible framework. our framework is based on a refinement cycle that allows for adaptively computing suitable translations of increasing size. our experiments on temporal ipc domains show that the resulting translations to timed automata often become succinct, resulting in promising performance when applied with the directed model checker mcta. advanced factoring strategies for decoupled search using linear programming star-topology decoupled state space search decomposes a planning task and searches over the component state spaces instead of multiplying the state variables. this can lead to an exponential reduction of the search effort. to do so, in a preprocess before the search, the given planning task needs to be decomposed into factors, such that the interaction between these factors forms a star topology. prior work has identified several ways to automatically decompose planning tasks, however, was not able to release the full potential of decoupled search. we try to close this gap by introducing an integer linear programming formulation of the factoring process, allowing us to explicitly specify the properties that a factoring should have. we prove that our approach returns the factoring that maximizes the number of factors, if this is the objective, and employ two other properties to assess the quality of a factoring. our experimental evaluation shows that this leads to superior performance and substantially increases the applicability of decoupled search. foundations for restraining bolts: reinforcement learning with ltlf/ldlf restraining specifications in this work we investigate on the concept of “restraining bolt”, envisioned in science fiction. specifically we introduce a novel problem in ai. we have two distinct sets of features extracted from the world, one by the agent and one by the authority imposing restraining specifications (the “restraining bolt”). the two sets are apparently unrelated since of interest to independent parties, however they both account for (aspects of) the same world. we consider the case in which the agent is a reinforcement learning agent on the first set of features, while the restraining bolt is specified logically using lineartimelogiconfinitetracesltlf/ldlf overthesecond set of features. we show formally, and illustrate with examples, that, under general circumstances, the agent can learn while shaping its goals to suitably conform (as much as possible) to the restraining bolt specifications. resource constrained deep reinforcement learning in urban environments, supply resources have to be constantly matched to the ""right"" locations (where customer demand is present) so as to improve quality of life. for instance, ambulances have to be matched to base stations regularly so as to reduce response time for emergency incidents in ems (emergency management systems); vehicles (cars, bikes, scooters etc.) have to be matched to docking stations so as to reduce lost demand in shared mobility systems. such problem domains are challenging owing to the demand uncertainty, combinatorial action spaces (due to allocation) and constraints on allocation of resources (e.g., resource capacity, minimum and maximum number of resources at locations and regions). existing systems typically employ myopic and greedy optimization approaches to optimize allocation of supply resources to locations. such approaches typically are unable to handle surges or variances in demand patterns well. recent research has demonstrated the ability of deep rl methods in adapting well to highly uncertain environments. however, existing deep rl methods are unable to handle combinatorial action spaces and constraints on allocation of resources. to that end, we have developed three approaches on top of the well known actor critic approach, ddpg (deep deterministic policy gradient) that are able to handle constraints on resource allocation. more importantly, we demonstrate that they are able to outperform leading approaches on simulators validated on semi-real and real data sets. symbolic planning with axioms axioms are an extension for classical planning models that allow for modeling complex preconditions and goals exponentially more compactly. although axioms were introduced in planning more than a decade ago, modern planning techniques rarely support axioms, especially in cost-optimal planning. symbolic search is a popular and competitive optimal planning technique based on the manipulation of sets of states. in this work, we extend symbolic search algorithms to support axioms natively. we analyze different ways of encoding derived variables and axiom rules to evaluate them in a symbolic representation. we prove that all encodings are sound and complete, and empirically show that the presented approach outperforms the previous state of the art in costoptimal classical planning with axioms. finding centroids and minimum covering states in planning in automated planning, the most common task consists of finding a plan that achieves a set of goals. in this paper, we focus on a different task; that of finding states that minimize some goal-related metric. first, we present some domains for which that task is useful. second, we propose two of such types of states: (1) centroid states, which minimize the distance to all the goals in the problem; and (2) minimum covering states, which minimize the maximum distance to any of the goals. third, we define optimal and suboptimal algorithms to find such states. finally, we show some experimental results in planning instances from different domains. a stochastic dual dynamic integer programming for the uncapacitated lot-sizing problem with uncertain demand and costs we study the uncapacitated lot-sizing problem with uncertain demand and costs. we consider a multi-stage decision process and rely on a scenario tree to represent the uncertainty. we propose to solve this stochastic combinatorial optimization problem thanks to a new extension of the stochastic dual dynamic integer programming algorithm. our results show that this approach can provide good quality solutions in a reasonable time for large-size instances. zac: a zone path construction approach for effective real-time ride sharing real-time ridesharing systems such as uberpool, lyft line, grabshare have become hugely popular as they reduce the costs for customers, improve per trip revenue for drivers and reduce traffic on the roads by grouping customers with similar itineraries. the key challenge in these systems is to group the right requests to travel in available vehicles in real time, so that the objective (e.g., requests served, revenue or delay) is optimized. the most relevant existing work has focused on generating as many relevant feasible (with respect to available delay for customers) combinations of requests (referred to as trips) as possible in real-time. since the number of trips increases exponentially with the increase in vehicle capacity and number of requests, unfortunately, such an approach has to employ ad hoc heuristics to identify relevant trips.

to that end, we propose an approach that generates many zone (abstraction of individual locations) paths – where each zone path can represent multiple trips (combinations of requests) – and assigns available vehicles to these zone paths to optimize the objective. the key advantage of our approach is that these zone paths are generated using a combination of offline and online methods, consequently allowing for the generation of many more relevant combinations in real-time than competing approaches. we demonstrate that our approach outperforms (with respect to both objective and runtime) the current best approach for ridesharing on both real world and synthetic datasets. counterexample-guided abstraction refinement for pattern selection in optimal classical planning we describe a new algorithm for generating pattern collections for pattern database heuristics in optimal classical planning. the algorithm uses the counterexample-guided abstraction refinement (cegar) principle to guide the pattern selection process. our experimental evaluation shows that a single run of the cegar algorithm can compute informative pattern collections in a fairly short time. using multiple cegar algorithm runs, we can compute much larger pattern collections, still in shorter time than existing approaches, which leads to a planner that outperforms the state-of-the-art pattern selection methods by a significant margin. reinforcement learning based querying in camera networks for efficient target tracking surveillance camera networks are a useful monitoring infrastructure that can be used for various visual analytics applications, where high-level inferences and predictions could be made based on target tracking across the network. most multi-camera tracking works focus on re-identification problems and trajectory association problems. however, as camera networks grow in size, the volume of data generated is humongous, and scalable processing of this data is imperative for deploying practical solutions. in this paper, we address the largely overlooked problem of scheduling cameras for processing by selecting one where the target is most likely to appear next. the inter-camera handover can then be performed on the selected cameras via re-identification or another target association technique. we model this scheduling problem using reinforcement learning and learn the camera selection policy using q-learning. we do not assume the knowledge of the camera network topology but we observe that the resulting policy implicitly learns it. we evaluate our approach using nlpr mct dataset, which is a real multi-camera multi-target tracking benchmark and show that the proposed policy substantially reduces the number of frames required to be processed at the cost of a small reduction in recall. privacy leakage of search-based multi-agent planning algorithms privacy-preserving multi-agent planning (pp-map) has recently gained the attention of the research community, resulting in a number of pp-map planners and theoretical works. many such planners lack strong theoretical guarantees, thus in order to compare their abilities w.r.t. privacy, a versatile and practical metric is crucial. in this work, we propose such a metric, building on the existing theoretical work. we generalize and implement the approach in order to be applicable on real planning domains and provide an evaluation of stateof-the-art pp-map planners over the standard set of benchmarks. the evaluation shows that the proposed privacy leakage metric is able to provide comparison of pp-map planners and reveal important properties. lagrangian decomposition for optimal cost partitioning optimal cost partitioning of classical planning heuristics has been shown to lead to excellent heuristic values but is often prohibitively expensive to compute. lagrangian decomposition and lagrangian relaxation are classical tools in mathematical programming that apply to optimization problems with a special block structure. we analyze the application of lagrangian decomposition to cost partitioning in the context of operator-counting heuristics and interpret lagrangian multipliers as cost functions for the combined heuristics. this allows us to view the computation of an optimal cost partitioning as an iterative process that can be seeded with any cost partitioning and improves over time. for non-negative cost partitioning, we derive an any-time algorithm to compute an optimal cost partitioning of abstraction heuristics without involving an lp solver. in each iteration, the computation reduces to independent shortest path problems in all abstractions. finally, we discuss the extension to general cost functions. on computational complexity of automorphism groups in classical planning symmetry based pruning is a family of powerful methods for reducing search effort in planning as heuristic search. applying these methods requires first establishing an automorphism group that is then used for pruning within the search process. despite the growing popularity of state-space symmetries in planning techniques, the computational complexity of finding the automorphism group of a compactly represented planning task has not been formally established. in a series of reductions, we show that computing the automorphism group of a grounded planning task is gi-hard. furthermore, we discuss the presentations of these symmetry groups and list some of their drawbacks. solution approaches for an automotive paint shop scheduling problem in the paint shops of the automotive supply industry a large number of synthetic material pieces need to be painted every day to provide the large variety of items required for car manufacturing. because of the sophisticated automated production process and the tight due dates requested by car manufacturers, finding an optimized production schedule becomes a challenging task that is at the present time performed by multiple human planners. in this paper we formulate and solve a novel real life paint shop scheduling problem from the automotive supply industry which introduces unique constraints and objectives that do not appear in the existing literature. additionally, we provide a new collection of benchmark instances based on real life planning scenarios that can be used to evaluate solution techniques for the problem. exact methods are only able to solve few of the smaller instances in reasonable running time. therefore, we propose a metaheuristic method based on local search that uses novel neighborhood relations and various ways to escape local optima. our approach is able to provide feasible solutions for all instances within reasonable running time. eliminating redundant actions in partially ordered plans – a complexity analysis in this paper we study the computational complexity of post-optimizing partially ordered plans, i.e., we investigate the problem that is concerned with detecting and deleting unnecessary actions. for totally ordered plans it can easily be tested in polynomial time whether a single action can be removed without violating executability. identifying an executable sub-plan, i.e., asking whether k plan steps can be removed, is known to be np-hard. we investigate the same questions for partially ordered input plans, as they are created by many search algorithms or used by real-world applications – in particular time-critical ones that exploit parallelism of non-conflicting actions. more formally, we investigate the computational complexity of removing an action from a partially ordered solution plan in which every linearization is a solution in the classical sense while allowing ordering insertions afterwards to repair arising executability issues. it turns out that this problem is np-complete – even if just a single action is removed – and thereby show that this reasoning task is harder than for totally ordered plans. moreover, we identify the structural properties responsible for this hardness by providing a fixed-parameter tractability (fpt) result. fast feature selection for linear value function approximation linear value function approximation is a standard approach to solving reinforcement learning problems with large state spaces. since designing good approximation features is difficult, automatic feature selection is an important research topic. we propose a new method for feature selection, which is based on a low-rank factorization of the transition matrix. our approach derives features directly from high-dimensional raw inputs, such as image data. the method is easy to implement using svd, and our experiments show that it is faster and more stable than alternative methods. on compiling away pddl3 qualitative preferences without using automata we address the problem of propositional planning extended with the class of soft temporally extended goals supported in pddl3, also called qualitative preferences since ipc-5. such preferences are useful to characterise plan quality by allowing the user to express certain soft constraints on the state trajectory of the desired solution plans. we propose and evaluate a compilation approach that extends previous work on compiling soft reachability goals and always goals to the full set of pddl3 qualitative preferences. this approach directly compiles qualitative preferences into propositional planning without using automata to represent the trajectory constraints. moreover, since no numerical fluent is used, it allows many existing strips planners to immediately address planning with preferences without changing their algorithms or codef. an experimental analysis presented in the paper evaluates the performance of state-of-the-art propositional planners supporting action costs using our compilation of pddl 3 qualitative preferences. the results indicate that the proposed approach is highly competitive with respect to current planners that natively support the considered class of preference, as well as with a recent automata-based compilation approach. discovery of optimal solution horizons in non-stationary markov decision processes with unbounded rewards infinite-horizon non-stationary markov decision processes provide a general framework to model many real-life decision-making problems, e.g., planning equipment maintenance. unfortunately, these problems are notoriously difficult to solve, due to their infinite dimensionality. often, only the optimality of the initial action is of importance to the decision-maker: once it has been identified, the procedure can be repeated to generate a plan of arbitrary length. the optimal initial action can be identified by finding a time horizon so long that data beyond it has no effect on the initial decision. this horizon is known as a solution horizon and can be discovered by considering a series of truncations of the problem until a stopping rule guaranteeing initial decision optimality is satisfied. we present such a stopping rule for problems with unbounded rewards. given a candidate policy, the rule uses a mathematical program that searches for other possibly optimal initial actions within the space of feasible truncations. if no better action can be found, the candidate action is deemed optimal. our rule runs faster than comparable rules and discovers shorter, more efficient solution horizons. best-first width search for multi agent privacy-preserving planning in multi-agent planning, preserving the agents’ privacy has become an increasingly popular research topic. for preserving the agents’ privacy, agents jointly compute a plan that achieves mutual goals by keeping certain information private to the individual agents. unfortunately, this can severely restrict the accuracy of the heuristic functions used while searching for solutions. it has been recently shown that, for centralized planning, the performance of goal oriented search can be improved by combining goal oriented search and width-based search. the combination of these techniques has been called best-first width search. in this paper, we investigate the usage of best-first width search in the context of (decentralised) multi-agent privacy-preserving planning, addressing the challenges related to the agents’ privacy and performance. in particular, we show that best-first width search is a very effective approach over several benchmark domains, even when the search is driven by heuristics that roughly estimate the distance from goal states, computed without using the private information of other agents. an experimental study analyses the effectiveness of our techniques and compares them with the state-of-the-art. mixed integer programming versus evolutionary computation for optimizing a hard real-world staff assignment problem assigning staff to engagements according to hard constraints while optimizing several objectives is a task encountered by many companies on a regular basis. simplified versions of such assignment problems are np-hard. despite this, a typical approach to solving them consists of formulating them as mixed integer programming (mip) problems and using a state-of-the-art solver to get solutions that closely approximate the optimum. in this paper, we consider a complex real-world staff assignment problem encountered by the professional service company kpmg, with the goal of finding an algorithm that solves it faster and with a better solution than a commercial mip solver. we follow the evolutionary algorithm (ea) metaheuristic and design a search heuristic which iteratively improves a solution using domain-specific mutation operators. furthermore, we use a flow algorithm to optimally solve a subproblem, which tremendously reduces the search space for the ea. for our real-world instance of the assignment problem, given the same total time budget of 100 hours, a parallel ea approach finds a solution that is only 1.7 % away from an upper bound for the (unknown) optimum within under five hours, while the mip solver gurobi still has a gap of 10.5 %. learning heuristic functions for mobile robot path planning using deep neural networks resorting to certain heuristic functions to guide the search, the computation efficiency of prevailing path planning algorithms such as a*, d* and their variants is solely determined by how good the heuristic function approximates the true path cost. in this study, we propose a novel approach to learn heuristic functions using a deep neural network (dnn) to improve the computation efficiency. even though dnns have been widely used for object segmentation, natural language processing, and perception, their role in helping to solve path planning has not been well investigated.  this work shows how dnns can be applied to path planning problems and what kind of loss functions is suitable for learning such a heuristic. our preliminary results show that an appropriately designed and trained dnn can learn a heuristic which effectively guides conventional path planning algorithms and speeds up the path generation. oversubscription planning as classical planning with multiple cost functions the aim of classical planning is to minimize the summed cost of operators among those plans that achieve a fixed set of goals. oversubscription planning (osp), on the other hand, seeks to maximize the utility of the set of facts achieved by a plan, while keeping the cost of the plan at or below some specified bound. here, we investigate the use of reformulations that yield planning problems with two separate cost functions, but no utilities, for solving osp tasks. such reformulations have also been proposed in the context of netbenefit planning, where the planner tries to maximize the difference between the utility achieved and the cost of the plan. one of our reformulations is adapted directly from that setting, while the other is novel. in both cases, they allow for easy adaptation of existing classical planning heuristics to the osp problem within a simple branch and bound search. we validate our approach using state of the art admissible heuristics in this framework, and report our results. planning under ltl environment specifications planning domains represent what an agent assumes or believes about the environment it acts in. in the presence of nondeterminism, additional temporal assumptions, such as fairness, are often expressed as extra conditions on the domain. here we consider environment specifications expressed in arbitrary ltl, which generalize many forms of environment specifications, including classical specifications of nondeterministic domains, fairness, and other forms of linear-time constraints on the domain itself. existing literature typically implicitly or explicitly considers environment specifications as constraints on possible traces. in contrast, in spite of the fact that we use a linear-time formalism, we propose to consider environment specifications as specifications of environment strategies. planning in this framework is the problem of computing an agent strategy that achieves its goal against all environment strategies satisfying the specification. we study the mathematical and computational properties of planning in this general setting. we observe that not all ltl formulas correspond to legitimate environment specifications, and formally characterize the ones that do. moreover, we show that our notion of planning generalizes the classical notion of church’s synthesis, and that in spite of this one can still solve it optimally using classical church’s synthesis. an exact algorithm to make a trade-off between cost and probability in ssps in stochastic sequential decision problems, such as stochastic shortest path problems, gubs (goal with utility-based semantic) criterion considers a trade-off between probabilityto-goal and cost-to-goal using a goal semantic based on expected utility theory (eut); in such a semantic, goal paths have priority over non-goal paths, but it implies neither maxprob criterion nor dual criterion. whereas evaluation criteria based on a sounding theory such as eut are desirable, optimal policies under gubs are non-stationary. non-stationary solutions are undesirable because there is not always a finite representation and, when it is not the case, the representation may be too large to be stored. considering exponential cost utility, we contribute with: (i) the first exact algorithm to obtain finite optimal policies for gubs criterion, and (ii) four strategies to find sub-optimal policies. we conduct experiments on one synthetic problem to evaluate each strategy. although optimal solutions have a high memory cost, sub-optimal policies can save memory space with a small decrease in performance. a multi-label a* algorithm for multi-agent pathfinding given a set of agents, the multi-agent pathfinding problem consists in determining, for each agent, a path from its start location to its assigned goal while avoiding collisions with other agents. recent work has studied variants of the problem in which agents are assigned a sequence of goals (tasks) that become available over time, such as the online multiagent pickup and delivery (mapd) problem. in this paper, we propose a multi-label a* algorithm (mla*) for this problem. it extends the classic a* algorithm by allowing the computation of paths with multiple ordered goals (such as a pickup and delivery). moreover, we develop a new h-value-based centralized heuristic for the mapd. computational experiments show that our proposed mla* obtains substantial improvements in terms of makespan and service time as compared to existing methods, while being more computationally efficient. on instances with a thousand tasks and hundreds of agents, our method reduces the average service time by 43% compared to the state of the art, with considerably less computational effort. bridging the gap between abstractions and critical-path heuristics via hypergraphs abstractions and critical-path heuristics are among the most important families of admissible heuristics in classical planning. in this paper, we present a new family of heuristics, which we name hyperabstractions, given by the combination of the principal ideas underlying abstractions and critical-path heuristics. hyperabstractions approximate goal distances through a mapping from states to sets of abstract states. the abstract transition behavior forms a relation between abstract states and sets of abstract states, and is formally represented via the notion of hypergraphs. we show that both abstractions and critical-path heuristics can naturally be expressed as members of this family. moreover, we devise a method to construct hyperabstractions, using either a set of abstractions or a critical-path heuristic as a seed, in a way that guarantees that the resulting distance estimations dominate those of the input heuristics, sometimes even strictly. by finding suitable cost partitionings for hyperabstraction heuristics, this dominance result is preserved even in comparison to the additive combination of the input heuristics. our experiments indicate the potential of this new class of heuristics, opening a wide range of future research topics. goal reasoning in a clips-based executive for integrated planning and execution the close integration of planning and execution is a challenging problem. key questions are how to organize and explicitly represent the program flow to enable reasoning about it, how to dynamically create goals from run-time information and decide on-line which to pursue, and how to unify representations used during planning and execution. in this work, we present an integrated system that uses a goal reasoning model which represents this flow and supports dynamic goal generation. with an explicit world model representation, it allows reasoning about the current state of the world, the progress of the execution flow, and what goals should be pursued – or postponed or abandoned. our executive implements a specific goal lifecycle with compound goal types that combine sub-goals by conjunctions, disjunctions, concurrency, or that impose temporal constraints. goals also provide a frame of reference for execution monitoring. the current system can utilize pddl as the underlying modeling language with extensions to aid execution and it contains well-defined extension points for domain-specific code. it has been used successfully in several scenarios. learning interpretable models expressed in linear temporal logic we examine the problem of learning models that characterize the high-level behaviour of a system based on observation traces. our aim is to develop models that are human interpretable. to this end, we introduce the problem of learning a linear temporal logic (ltl) formula that parsimoniously captures a given set of positive and negative example traces. our approach to learning ltl exploits a symbolic state representation, searching through a space of labeled skeleton formulae to construct an alternating automaton that models observed behaviour, from which the ltl can be read off. construction of interpretable behaviour models is central to a diversity of applications related to planning and plan recognition. we showcase the relevance and significance of our work in the context of behaviour description and discrimination: i) active learning of a human-interpretable behaviour model that describes observed examples obtained by interaction with an oracle ii) passive learning of a classifier that discriminates individual agents, based on the human-interpretable signature way in which they perform particular tasks. experiments demonstrate the effectiveness of our symbolic model learning approach in providing human-interpretable models and classifiers from reduced example sets. entropy based independent learning in anonymous multi-agent settings efficient sequential matching of supply and demand is a problem of interest in many online to offline services. for instance, uber, lyft, grab for matching taxis to customers; ubereats, deliveroo, foodpanda etc for matching restaurants to customers. in these online to offline service problems, individuals who are responsible for supply (e.g., taxi drivers, delivery bikes or delivery van drivers) earn more by being at the ”right” place at the ”right” time. we are interested in developing approaches that learn to guide individuals to be in the ”right” place at the ”right” time (to maximize revenue) in the presence of other similar ”learning” individuals and only local aggregated observation of other agents states (e.g., only number of other taxis in same zone as current agent). existing approaches in multi-agent reinforcement learning (marl) are either not scalable (e.g., about 40000 taxis/cars for a city like singapore) or assumptions of common objective (or action coordination) or centralized learning are not viable. a key characteristic of the domains of interest is that the interactions between individuals are anonymous, i.e., the outcome of an interaction (competing for demand) is dependent only on the number and not on the identity of the agents. we model these problems using the anonymous marl (aymarl) model. to ensure scalability and individual learning, we focus on improving performance of independent reinforcement learning methods, specifically deep q-networks (dqn) and advantage actor critic (a2c) for aymarl. the key contribution of this paper is in employing principle of maximum entropy to provide a general framework of independent learning that is both empirically effective (even with only local aggregated information of agent state distribution) and theoretically justified. finally, our approaches provide a significant improvement with respect to joint and individual revenue on a generic simulator for online to offline services and a real world taxi problem over existing approaches. more importantly, this is achieved while having the least variance in revenues earned by the learning individuals, an indicator of fairness. pomdp-based candy server: lessons learned from a seven day demo an autonomous robot must decide a good strategy to achieve its long term goal, despite various types of uncertainty. the partially observable markov decision processes (pomdps) is a principled framework to address such a decision making problem. despite the computational intractability of solving pomdps, the past decade has seen substantial advancement in pomdp solvers. this paper presents our experience in enabling on-line pomdp solving to become the sole motion planner for a robot manipulation demo at ieee simpar and icra 2018. the demo scenario is a candy-serving robot: a 6-dofs robot arm must pick-up a cup placed on a table by a user, use the cup to scoop candies from a box, and put the cup of candies back on the table. the average perception error is _3cm (≈ the radius of the cup), affecting the position of the cup and the surface level of the candies. this paper presents a strategy to alleviate the curse of history issue plaguing this scenario, the perception system and its integration with the planner, and lessons learned in enabling an online pomdp solver to become the sole motion planner of this entire task. the pomdp-based system were tested through a 7 days live demo at the two conferences. in this demo, 150 runs were attempted and 98% of them were successful. we also conducted further experiments to test the capability of our pomdp-based system when the environment is relatively cluttered by obstacles and when the user moves the cup while the robot tries to pick it up. in both cases, our pomdp-based system reaches a success rate of 90% and above. a logical semantics for pddl+ pddl+ is an extension of pddl2.1 which incorporates fully-featured autonomous processes and allows for better modelling of mixed discrete-continuous domains. unlike pddl2.1, pddl+ lacks a logical semantics, relying instead on state-transitional semantics enriched with hybrid automata semantics for the continuous states. this complex semantics makes analysis and comparisons to other action formalisms difficult. in this paper, we propose a natural extension of reiter’s situation calculus theories inspired by hybrid automata. the kinship between pddl+ and hybrid automata allows us to develop a direct mapping between pddl+ and situation calculus, thereby supplying pddl+ with a logical semantics and the situation calculus with a modern way of representing autonomous processes. we outline the potential benefits of the mapping by suggesting a new approach to effective planning in pddl+. measuring and optimizing durability against scheduling disturbances flexibility is a useful and common metric for measuring the amount of slack in a simple temporal network (stn) solution space. we extend this concept to specific schedules within an stn’s solution space, developing a related notion of durability that captures an individual schedule’s ability to withstand disturbances and still remain valid. we identify practical sources of scheduling disturbances that motivate the need for durable schedules, and create a geometrically-inspired empirical model that enables testing a given schedule’s ability to withstand these disturbances. we develop a number of durability metrics and use these to characterize and compute specific schedules that we expect to have high durability. using our model of practical disturbances, we show that our durability metrics strongly predict a schedule’s resilience to practical scheduling disturbances. we also demonstrate that the schedules we identify as having high durability are up to three times more resilient to disturbances than an arbitrarily chosen schedule is. pomhdp: search-based belief space planning using multiple heuristics robots operating in the real world encounter substantial uncertainty that cannot be modeled deterministically before the actual execution. this gives rise to the necessity of robust motion planning under uncertainty also known as belief space planning. belief space planning can be formulated as partially observable markov decision process (pomdp). however, computing optimal policies for non-trivial pomdps is computationally intractable. building upon recent progress from the search community, we propose a novel anytime pomdp solver, partially observable multi-heuristic dynamic programming (pomhdp), that leverages multiple heuristics to efficiently compute high-quality solutions while guaranteeing asymptotic convergence to an optimal policy. through iterative forward search, pomhdp utilizes domain knowledge to solve pomdps with specific goals and an infinite horizon. we demonstrate the efficacy of our proposed framework on a real-world, highly-complex, truck unloading application. learning classical planning strategies with policy gradient a common paradigm in classical planning is heuristic forward search. forward search planners often rely on simple best-first search which remains fixed throughout the search process. in this paper, we introduce a novel search framework capable of alternating between several forward search approaches while solving a particular planning problem. selection of the approach is performed using a trainable stochastic policy, mapping the state of the search to a probability distribution over the approaches. this enables using policy gradient to learn search strategies tailored to a specific distributions of planning problems and a selected performance metric, e.g. the ipc score. we instantiate the framework by constructing a policy space consisting of five search approaches and a two-dimensional representation of the planner’s state. then, we train the system on randomly generated problems from five ipc domains using three different performance metrics. our experimental results show that the learner is able to discover domain-specific search strategies, improving the planner’s performance relative to the baselines of plain bestfirst search and a uniform policy. dream: an algorithm for mitigating the overhead of robust rescheduling generating and executing temporal plans is difficult in uncertain environments. the current state-of-the-art algorithm for probabilistic temporal networks maintains a high success rate by rescheduling frequently as uncertain events are resolved, but this approach involves substantial resource overhead due to computing and communicating new schedules between agents. aggressive rescheduling could thus reduce overall mission duration or success in situations where agents have limited energy, computing power, and may not be feasible when communication is limited. in this paper, we propose new approaches for heuristically deciding when rescheduling is most efficacious. we propose two compatible approaches, allowable risk and sufficient change, that can be employed in combination to compromise between the computation rate, the communication rate, and success rate for new schedules. we show empirically that both approaches allow us to gracefully trade success rate for lower computation and/or communication as compared to a state-of-the-art dynamic scheduling algorithm. cyber-physical planning: deliberation for hybrid systems with a continuous numeric state cyber-physical systems pose unique deliberation challenges, where complex strategies must be autonomously derived and executed in the physical world, relying on continuous state representations and subject to safety and security constraints. robots are a typical example of cyber-physical system where high-level decisions must be reconciled with motion-level decisions in order to provide guarantees on the validity and efficiency of the plan. in this work we propose techniques to refine a high-level plan into a continuous state trajectory. the refinement is done by translating a high-level plan into a nonlinear optimization problem with constraints that can encode the intrinsic limitations and dynamics of the system as well as the rules for its continuous control. the refinement process either succeeds or yields an explanation that we exploit to refine the search space of a high-level task planner. we evaluate our approach on existing pddl+ benchmarks as well as on a more realistic and challenging rover navigation problem. trajectory tracking control for robotic vehicles using counterexample guided training of neural networks we investigate approaches to train neural networks for controlling vehicles to follow a fixed reference trajectory robustly, while respecting limits on their velocities and accelerations. here robustness means that if a vehicle starts inside a fixed region around the reference trajectory, it remains within this region while moving along the reference from an initial set to a target set. we consider the combination of two ideas in this paper: (a) demonstrations of the correct control obtained from a model-predictive controller (mpc) and (b) falsification approaches that actively search for violations of the property, given a current candidate. thus, our approach builds an initial training set using the mpc loop and creates a first candidate neural network controller. this controller is repeatedly analyzed using falsification that searches for counterexample trajectories, and the resulting counterexamples are used to create new training examples. this process proceeds iteratively until the falsifier no longer succeeds within a given computational budget. we propose falsification approaches using a combination of random sampling and gradient descent to systematically search for violations. we evaluate our combined approach on a variety of benchmarks that involve controlling dynamical models of cars and quadrotor aircraft. robust bayes-adaptive planning under model uncertainty planning under model uncertainty is a fundamental problem across many applications of decision making and learning. in this paper, we propose the robust adaptive monte carlo planning (ramcp) algorithm, which allows computation of risk-sensitive bayes-adaptive policies that optimally trade off exploration, exploitation, and robustness. ramcp formulates the risk-sensitive planning problem as a two-player zero-sum game, in which an adversary perturbs the agent’s belief over the models. we introduce two versions of the ramcp algorithm. the first, ramcp-f, converges to an optimal risk-sensitive policy without having to rebuild the search tree as the underlying belief over models is perturbed. the second version, ramcp-i, improves computational efficiency at the cost of losing theoretical guarantees, but is shown to yield empirical results comparable to ramcp-f. ramcp is demonstrated on an n-pull multi-armed bandit problem, as well as a patient treatment scenario. generalized lazy search for robot motion planning: interleaving search and edge evaluations via event-based toggles lazy search algorithms are efficient at solving problems where edge evaluation is the bottleneck in computation, as is the case in robotic motion planning. the optimal algorithm in this class, lazysp, does so by lazily restricting edge evaluation only to the shortest path. however, this comes at the expense of search effort, i.e. lazysp has to recompute the search tree every time an edge is found to be invalid. this can get prohibitively expensive when dealing with large graphs or highly-cluttered environments. our key insight is that both edge evaluation and search effort must be balanced to minimize the total planning time. our contribution is two-fold. first, we propose a framework, generalized lazy search (gls), that seamlessly toggles between search and evaluation to manage wasted efforts. we show that for a choice of toggle, gls is provably more efficient than lazysp. secondly, we leverage prior experience in terms of edge probabilities to derive policies within the gls framework that minimize expected planning time. we show that gls armed with such priors significantly outperforms competitive baselines on a number of simulated environments in r2 and 7-dof manipulation. open-world reasoning for service robots a service robot accepting verbal commands from a human operator is likely to encounter requests that reference objects not currently represented in its knowledge base. in domestic or office settings, the construction of a complete knowledge base would be cumbersome and unlikely to succeed in most real-world deployments. the world that such a robot operates in is thus “open” in the sense that some objects that it must act on in the real world are not described in its internal representation. however, when an operator gives a command referencing an object that the robot has not yet observed (and thus not incorporated into its knowledge base), we can think of the object as being hypothetical to the robot. this paper presents a novel method for closing the robot’s world model for planning purposes by introducing hypothetical objects into the robot’s knowledge base, reasoning about these hypothetical objects, and acting on these hypotheses in the real world. we use our implementation of this method on a domestic service robot as an illustrative demonstration to explore how it works in practice. approximate gradient descent convergence dynamics for adaptive control on heterogeneous networks adaptive control is a classical control method for complex cyber-physical systems, including transportation networks. in this work, we analyze the convergence properties of such methods on exemplar graphs, both theoretically and numerically. we first illustrate a limitation of the standard backpressure algorithm for scheduling optimization, and prove that a re-scaling of the model state can lead to an improvement in the overall system optimality by a factor of at most o(k) depending on the network parameters, where k characterizes the network heterogeneity. we exhaustively describe the associated transient and steady-state regimes, and derive convergence properties within this generalized class of backpressure algorithms. extensive simulations are conducted on both a synthetic network and a more realistic large-scale network modeled on the manhattan grid on which theoretical results are verified. using bi-directional information exchange to improve decentralized schedule-driven traffic control recent work in decentralized, schedule-driven traffic control has demonstrated the ability to improve the efficiency of traffic flow in complex urban road networks. in this approach, a scheduling agent is associated with each intersection. each agent senses the traffic approaching its intersection and in real-time constructs a schedule that minimizes the cumulative wait time of vehicles approaching the intersection over the current look-ahead horizon. in order to achieve network level coordination in a scalable manner, scheduling agents communicate only with their direct neighbors. each time an agent generates a new intersection schedule it communicates its expected outflows to its downstream neighbors as a prediction of future demand and these outflows are appended to the downstream agent’s locally perceived demand. in this paper, we extend this basic coordination algorithm to additionally incorporate the complementary flow of information reflective of an intersection’s current congestion level to its upstream neighbors. we present an asynchronous decentralized algorithm for updating intersection schedules and congestion level estimates based on these bi-directional information flows. by relating this algorithm to the self-optimized decision making of the basic operation, we are able to approach network-wide optimality and reduce inefficiency due to strictly self-interested intersection control decisions. size-independent neural transfer for rddl planning neural planners for rddl mdps produce deep reactive policies in an offline fashion. these scale well with large domains, but are sample inefficient and time-consuming to train from scratch for each new problem. to mitigate this, recent work has studied neural transfer learning, so that a generic planner trained on other problems of the same domain can rapidly transfer to a new problem. however, this approach only transfers across problems of the same size. we present the first method for neural transfer of rddl mdps that can transfer across problems of different sizes. our architecture has two key innovations to achieve size independence: (1) a state encoder, which outputs a fixed length state embedding by max pooling over varying number of object embeddings, (2) a single parameter-tied action decoder that projects object embeddings into action probabilities for the final policy. on the two challenging rddl domains of sysadmin and game of life, our approach powerfully transfers across problem sizes and has superior learning curves over training from scratch. speeding up search-based motion planning via conservative heuristics weighted a* search (wa*) is a popular tool for robot motionplanning. its efficiency however depends on the quality of heuristic function used. in fact, it has been shown that the correlation between the heuristic function and the true costto-goal affects heavily the efficiency of the search, when used with a large weight on the heuristics. motivated by this observation, we investigate the problem of computing heuristics that explicitly aim to minimize the amount of efforts the search has to do to find a feasible plan. the key observation we exploit is that while heuristics tries to guide the search along what looks like an optimal path towards the goal, there are other paths that are clearly sub-optimal yet are much easier to compute. for example, in motion planning domains like footstep-planning for humanoids, a heuristic that guides the search along a path away from obstacles is less likely to encounter local minima compared with the heuristics that guides the search along an optimal but closeto-obstacles path. we utilize this observation to define the concept of conservative heuristics and propose a simple algorithm for computing such a heuristic function. experimental analysis on (1) humanoid footstep planning (simulation), (2) path planning for a uav (simulation), and a real-world experiment in footstep-planning for a nao robot shows the utility of the approach. cutting the size of compressed path databases with wildcards and redundant symbols path planning on gridmaps is a core ai problem, very popular in applications such as games. compressed path databases (cpds) represent a state-of-the-art approach to the problem, in terms of the speed of computing full optimal paths and individual optimal moves. despite significant improvements in recent years, the memory required to store a cpd can still be a bottleneck for large maps. we present an approach to improving the compression in cpds. our techniques use an extended notion of wildcards, and a novel concept called a redundant symbol. we implemented our ideas on top of a state-of-the-art cpd system. experiments demonstrate a substantial reduction of the size of cpds.